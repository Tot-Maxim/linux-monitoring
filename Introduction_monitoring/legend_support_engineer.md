# Легенда инженера по сопровождению ПО, работающего в отделе мониторинга

---

#### 1. **Общая информация о работе и отделе**
Я работаю инженером по сопровождению ПО в отделе мониторинга уже около двух лет. Наш отдел отвечает за обеспечение стабильной работы критически важных сервисов компании, а также за своевременное выявление и устранение инцидентов. Мы активно используем современные инструменты для мониторинга, автоматизации и управления инфраструктурой. 

Моя основная задача — поддерживать работоспособность всех систем, решать возникающие инциденты, внедрять релизы и следить за качеством работы серверов и приложений.

---

#### 2. **Распорядок дня**
Каждый день начинается с ежедневной встречи (дейлик: daily stand-up) с начальством и командой. На этой встрече мы обсуждаем текущие инциденты, задачи на день, а также прогресс по внедрению новых релизов. Тимлид ведет опрос каждого инженера и назначает новые задачи, спрашивает о текущих активностях и задачах подробно каждого. Дейлик идет от 30 минут до часа. После этого я проверяю дашборды в Grafana, чтобы убедиться, что все метрики в пределах нормы. Если есть какие-либо аномалии или инциденты, я сразу же начинаю их расследование.

Основные задачи дня:
- Мониторинг состояния систем через Prometheus и Grafana.
- Решение инцидентов, которые могут возникнуть в процессе работы.
- Подготовка и внедрение релизов через CI/CD-пайплайны.
- Взаимодействие с разработчиками для устранения проблем в коде.
- Участие в совещаниях по оптимизации инфраструктуры.

---

#### 3. **Стек отдела**
Наш отдел использует следующий стек технологий (внимание, если вы указываете этот стек в резюме, то от каждого инструмента, даже если вы с ним работали поверхностно слова должны отскакивать, как от зубов, хотя бы в трех предложениях, как минимум, учитесь импровизировать на ходу):

**Мониторинг:**
- **Grafana**: Для визуализации метрик и создания дашбордов.
- **Prometheus**: Для сбора метрик с серверов и приложений.
- **Node Exporter**: Для мониторинга состояния серверов.
- **Blackbox Exporter**: Для проверки доступности сервисов (HTTP, TCP, ICMP).
- **Nginx Exporter**: Для мониторинга производительности Nginx.
- **Postgres Exporter**: Для мониторинга баз данных PostgreSQL.

**Серверы:**
- **Nginx**: Балансировка нагрузки и проксирование трафика.
- **Kubernetes (k8s)**: Оркестрация контейнеров.
- **OpenShift**: Платформа для управления контейнерами.

**CI/CD:**
- **TeamCity**: Автоматизация сборки и тестирования.
- **Ansible**: Конфигурационное управление.
- **Docker**: Контейнеризация приложений.
- **Terraform**: Управление инфраструктурой как кодом.

**ОС:**
- **Debian**: Используется в разрезе стенда DEV в качестве песочницы.
- **CentOS**: Основная операционная система для серверов.

---

#### 4. **Вопросы к каждому инструменту**

##### **Grafana**
1. Как вы настраивали дашборды для мониторинга критических метрик?
   - Ответ: Я создавал дашборды, которые показывают использование CPU, RAM, дискового пространства и сетевой активности. Также добавлял графики для HTTP-статусов и времени отклика сервисов.

2. Как вы организовывали уведомления?
   - Ответ: Мы настроили алерты через Alertmanager, которые отправляют уведомления в Telegram и email, если метрики выходят за допустимые пределы.

3. Как вы решали проблемы с производительностью дашбордов?
   - Ответ: Оптимизировал запросы к Prometheus, уменьшая количество данных, которые нужно обрабатывать, и использовал агрегацию метрик.

4. Как вы интегрировали Grafana с другими инструментами?
   - Ответ: Мы интегрировали Grafana с Prometheus для сбора метрик и с Blackbox Exporter для мониторинга доступности сервисов.

5. Как вы обеспечивали безопасность дашбордов?
   - Ответ: Настроил RBAC (Role-Based Access Control), чтобы ограничить доступ к дашбордам только для авторизованных пользователей.

---

##### **Prometheus**
1. Как вы собирали метрики с серверов?
   - Ответ: Использовал Node Exporter для сбора метрик с серверов и настраивал scrape jobs в конфигурации Prometheus.

2. Как вы решали проблемы с нехваткой места для хранения метрик?
   - Ответ: Настроил retention policies и использовал компрессию данных для уменьшения объема хранимых метрик.

3. Как вы организовывали alerting?
   - Ответ: Создавал правила в Prometheus Rules для мониторинга критических метрик, таких как использование CPU выше 90% или недоступность сервисов.

4. Как вы решали проблемы с высокой нагрузкой на Prometheus?
   - Ответ: Добавлял больше серверов для шардинга данных и настраивал federation для распределенного сбора метрик.

5. Как вы тестировали новые правила алертинга?
   - Ответ: Использовал Prometheus Recording Rules для тестирования правил перед их применением в продакшене.

---

##### **Nginx**
1. Как была реализована балансировка нагрузки?
   - Ответ: Мы использовали Nginx с алгоритмом round-robin для равномерного распределения трафика между серверами.

2. Как вы решали проблемы с медленными ответами?
   - Ответ: Анализировал логи Nginx и оптимизировал конфигурацию keepalive и timeout.

3. Как вы настраивали мониторинг Nginx?
   - Ответ: Использовал Nginx Exporter для сбора метрик, таких как количество запросов, время отклика и ошибки.

4. Как вы обеспечивали безопасность Nginx?
   - Ответ: Настроил SSL/TLS, ограничил доступ по IP и использовал WAF для защиты от атак.

5. Как вы решали проблемы с падением Nginx?
   - Ответ: Анализировал логи и добавлял health checks для автоматического перезапуска.

---

##### **Kubernetes**
1. Как вы решали проблемы с деплоем приложений?
   - Ответ: Проверял логи подов и настраивал readiness probes для корректного старта приложений.

2. Как вы мониторили состояние кластера?
   - Ответ: Использовал Prometheus для сбора метрик с kube-state-metrics и Grafana для визуализации.

3. Как вы решали проблемы с производительностью кластера?
   - Ответ: Оптимизировал использование ресурсов через resource requests и limits.

4. Как вы настраивали CI/CD для Kubernetes?
   - Ответ: Использовал TeamCity для сборки образов Docker и Helm для деплоя в Kubernetes.

5. Как вы решали проблемы с нехваткой ресурсов?
   - Ответ: Добавлял новые ноды в кластер и настраивал autoscaling.

---

##### **TeamCity**
1. Как вы настраивали пайплайны для сборки проектов?
   - Ответ: Использовал build steps для выполнения команд сборки, тестирования и деплоя.

2. Как вы решали проблемы с зависанием билдов?
   - Ответ: Анализировал логи и увеличивал таймауты для длительных задач.

3. Как вы организовывали уведомления о статусе билдов?
   - Ответ: Настроил интеграцию с Slack для отправки уведомлений о завершении билдов.

4. Как вы решали проблемы с нехваткой ресурсов агентов?
   - Ответ: Добавлял новые агенты и настраивал параллельное выполнение задач.

5. Как вы тестировали новые пайплайны?
   - Ответ: Запускал тестовые билды в отдельной ветке перед деплоем в продакшен.

---

#### **Node Exporter**
1. Как вы собирали метрики с серверов?
   - Ответ: Использовал Node Exporter для сбора метрик, таких как использование CPU, RAM, дискового пространства и сетевой активности. Настроил его на всех серверах через Ansible.

2. Как вы решали проблемы с высоким потреблением ресурсов Node Exporter?
   - Ответ: Ограничивал частоту сбора данных и использовал фильтры для исключения ненужных метрик.

3. Как вы мониторили состояние Node Exporter?
   - Ответ: Добавлял метрики Node Exporter в Prometheus и создавал дашборды в Grafana для визуализации.

4. Как вы обновляли Node Exporter на серверах?
   - Ответ: Использовал Ansible для автоматического обновления версий Node Exporter на всех серверах.

5. Как вы решали проблемы с отсутствием данных от Node Exporter?
   - Ответ: Проверял логи Node Exporter, конфигурацию scrape jobs в Prometheus и статус сервиса на сервере.

---

#### **Blackbox Exporter**
1. Как вы проверяли доступность сервисов?
   - Ответ: Использовал Blackbox Exporter для проверки HTTP, TCP и ICMP. Настроил probes для каждого типа сервиса.

2. Как вы решали проблемы с ложными алертами от Blackbox Exporter?
   - Ответ: Настроил таймауты и пороговые значения для уменьшения количества ложных срабатываний.

3. Как вы интегрировали Blackbox Exporter с Prometheus?
   - Ответ: Добавил Blackbox Exporter как target в конфигурацию Prometheus и настроил соответствующие scrape jobs.

4. Как вы тестировали новые probes?
   - Ответ: Запускал тестовые probes в изолированной среде перед добавлением их в продакшен.

5. Как вы обеспечивали безопасность Blackbox Exporter?
   - Ответ: Ограничивал доступ к Blackbox Exporter через файрвол и использовал RBAC для управления доступом.

---

#### **Postgres Exporter**
1. Как вы собирали метрики с PostgreSQL?
   - Ответ: Использовал Postgres Exporter для сбора метрик, таких как количество подключений, время выполнения запросов и использование таблиц.

2. Как вы решали проблемы с производительностью базы данных?
   - Ответ: Анализировал метрики Postgres Exporter и оптимизировал запросы и индексы.

3. Как вы интегрировали Postgres Exporter с Prometheus?
   - Ответ: Настроил scrape jobs в Prometheus для сбора метрик с Postgres Exporter.

4. Как вы решали проблемы с отсутствием данных от Postgres Exporter?
   - Ответ: Проверял права доступа к базе данных и конфигурацию экспортера.

5. Как вы мониторили репликацию PostgreSQL?
   - Ответ: Добавлял метрики репликации в Postgres Exporter и настраивал алерты в Prometheus.

---

#### **Ansible**
1. Как вы автоматизировали развертывание серверов?
   - Ответ: Писал плейбуки Ansible для установки и настройки необходимых пакетов, конфигураций и сервисов.

2. Как вы решали проблемы с неудачными деплоями через Ansible?
   - Ответ: Проверял логи выполнения плейбуков и исправлял ошибки в конфигурации.

3. Как вы организовывали управление конфигурациями?
   - Ответ: Использовал роли и переменные Ansible для централизованного управления конфигурациями.

4. Как вы тестируете новые плейбуки?
   - Ответ: Запускал плейбуки в тестовой среде перед применением в продакшене.

5. Как вы обеспечивали безопасность при использовании Ansible?
   - Ответ: Использовал Vault для шифрования чувствительных данных и ограничивал доступ к репозиторию с плейбуками.

---

#### **Docker**
1. Как вы управляли контейнерами в продакшене?
   - Ответ: Использовал Docker Compose для оркестрации контейнеров и настраивал health checks для мониторинга состояния.

2. Как вы решали проблемы с перезапуском контейнеров?
   - Ответ: Настроил restart policies и добавлял мониторинг через Docker Exporter.

3. Как вы оптимизировали использование ресурсов Docker?
   - Ответ: Ограничивал CPU и RAM для контейнеров через параметры запуска.

4. Как вы обновляли образы Docker?
   - Ответ: Использовал CI/CD-пайплайн для сборки новых образов и их автоматического деплоя.

5. Как вы решали проблемы с нехваткой места на диске?
   - Ответ: Очищал старые образы и volumes через команды `docker system prune`.

---

#### **Terraform**
1. Как вы управляли инфраструктурой через Terraform?
   - Ответ: Писал конфигурации Terraform для создания и управления серверами, сетями и другими ресурсами.

2. Как вы решали проблемы с конфликтами состояний (state conflicts)?
   - Ответ: Использовал remote state в S3 и настраивал блокировки через DynamoDB.

3. Как вы тестировали новые конфигурации Terraform?
   - Ответ: Запускал `terraform plan` для проверки изменений перед применением.

4. Как вы организовывали модульность Terraform?
   - Ответ: Создавал модули для повторного использования конфигураций.

5. Как вы обеспечивали безопасность Terraform?
   - Ответ: Шифровал чувствительные данные через `sensitive` и хранил state файлы в защищенном месте.

---

#### **Debian/CentOS**
1. Как вы обновляли операционные системы?
   - Ответ: Использовал `apt` для Debian и `yum` для CentOS. Автоматизировал процесс через Ansible.

2. Как вы решали проблемы с зависимостями пакетов?
   - Ответ: Проверял логи и временно отключал конфликтующие пакеты.

3. Как вы мониторили состояние серверов?
   - Ответ: Использовал Node Exporter и настраивал алерты через Prometheus.

4. Как вы настраивали файрволы?
   - Ответ: Использовал `iptables` или `firewalld` в зависимости от ОС.

5. Как вы обеспечивали безопасность серверов?
   - Ответ: Регулярно обновлял системы, настраивал SELinux/AppArmor и ограничивал доступ по SSH.
